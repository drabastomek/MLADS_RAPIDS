{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVIDIA RAPIDS on Azure ML\n",
    "## MLADS Fall'19\n",
    "\n",
    "In this notebook we use NYC Taxi dataset to showcase some the speedup and the ease of converting the single-threaded `pandas` execution with GPU-accellerated ETL workload using `cudf` from RAPIDS.\n",
    "\n",
    "**AUTHORS**\n",
    "* Tom Drabas (Microsoft)\n",
    "* Brad Rees (NVIDIA)\n",
    "* John Zedlewski (NVIDIA)\n",
    "* Paul Mahler (NVIDIA)\n",
    "* Nick Becker (NVIDIA)\n",
    "* Chau Dang (NVIDIA)\n",
    "\n",
    "**GREATER TEAM**\n",
    "* Joshua Patterson (NVIDIA)\n",
    "* Keith Kraus (NVIDIA)\n",
    "* Michael Beaumont (NVIDIA)\n",
    "* Manuel Reyes Gomez (NVIDIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cudf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define global vars and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dtypes = OrderedDict(\n",
    "    [\n",
    "        ('vendor_id', 'int32'),\n",
    "        ('pickup_datetime', 'date'),\n",
    "        ('dropoff_datetime', 'date'),\n",
    "        ('passenger_count', 'int32'),\n",
    "        ('trip_distance', 'int32'),\n",
    "        ('pickup_longitude', 'float64'),\n",
    "        ('pickup_latitude', 'float64'),\n",
    "        ('rate_code', 'int32'),\n",
    "        ('store_and_fwd_flag', 'int32'),\n",
    "        ('dropoff_longitude', 'float64'),\n",
    "        ('dropoff_latitude', 'float64'),\n",
    "        ('payment_type', 'int32'),\n",
    "        ('fare_amount', 'float64'),\n",
    "        ('extra', 'float64'),\n",
    "        ('mta_tax', 'float64'),\n",
    "        ('tip_amount', 'float64'),\n",
    "        ('tolls_amount', 'float64'),\n",
    "        ('surcharge', 'float64'),\n",
    "        ('total_amount', 'float64')\n",
    "    ]\n",
    ")\n",
    "\n",
    "use_col  = [\n",
    "      'pickup_datetime'\n",
    "    , 'dropoff_datetime'\n",
    "    , 'passenger_count'\n",
    "    , 'trip_distance'\n",
    "    , 'pickup_longitude'\n",
    "    , 'pickup_latitude'\n",
    "    , 'rate_code'\n",
    "    , 'dropoff_longitude'\n",
    "    , 'dropoff_latitude'\n",
    "    , 'fare_amount'\n",
    "]\n",
    "\n",
    "query_frags = [\n",
    "    'fare_amount > 0 and fare_amount < 500',\n",
    "    'passenger_count > 0 and passenger_count < 6',\n",
    "    'pickup_longitude > -75 and pickup_longitude < -73',\n",
    "    'dropoff_longitude > -75 and dropoff_longitude < -73',\n",
    "    'pickup_latitude > 40 and pickup_latitude < 42',\n",
    "    'dropoff_latitude > 40 and dropoff_latitude < 42'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_message(msg, length=80, filler='#', pre_post=''):\n",
    "    print(f'{pre_post} {msg} {pre_post}'.center(length, filler))\n",
    "    \n",
    "def print_time(t_curr, t_next, t_start, length=80):\n",
    "    print('> Step time: {0}, elapsed time: {1}'\n",
    "          .format(str(t_curr - t_next), str(t_curr - t_start)).rjust(length, '-'))\n",
    "    \n",
    "def add_features(df, gpu):\n",
    "    df['pickup_datetime'] = df['pickup_datetime'].astype('datetime64[ms]')\n",
    "    \n",
    "    df['hour']  = df['pickup_datetime'].dt.hour\n",
    "    df['year']  = df['pickup_datetime'].dt.year\n",
    "    df['month'] = df['pickup_datetime'].dt.month\n",
    "    df['day']   = df['pickup_datetime'].dt.day\n",
    "    \n",
    "    #### BUG -- the below can be done on Titan V and Titan RTX but not P40 (Pascal)\n",
    "#     df['pickup_latitude_r']   = df['pickup_latitude']   // .01 * .01\n",
    "#     df['pickup_longitude_r']  = df['pickup_longitude']  // .01 * .01\n",
    "#     df['dropoff_latitude_r']  = df['dropoff_latitude']  // .01 * .01\n",
    "#     df['dropoff_longitude_r'] = df['dropoff_longitude'] // .01 * .01\n",
    "\n",
    "    #### WORKAROUND\n",
    "    df['pickup_latitude_r']   = (df['pickup_latitude']   / .01).astype('int') / 100.0\n",
    "    df['pickup_longitude_r']  = (df['pickup_longitude']  / .01).astype('int') / 100.0\n",
    "    df['dropoff_latitude_r']  = (df['dropoff_latitude']  / .01).astype('int') / 100.0\n",
    "    df['dropoff_longitude_r'] = (df['dropoff_longitude'] / .01).astype('int') / 100.0\n",
    "    \n",
    "    if gpu:\n",
    "        df = df.drop('pickup_datetime')\n",
    "        df = df.drop('dropoff_datetime')\n",
    "    else:\n",
    "        df = df.drop('pickup_datetime', axis=1)\n",
    "        df = df.drop('dropoff_datetime', axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define GPU workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gpu_workflow(data_path):\n",
    "    t_start = datetime.datetime.now()\n",
    "    print_message('LOADING DATA')\n",
    "    \n",
    "    taxi_df = cudf.read_csv(\n",
    "              os.path.join(data_path, '2016/yellow_tripdata_2016-01.csv')\n",
    "            , names=list(columns_dtypes.keys())\n",
    "            , dtype=list(columns_dtypes.values())\n",
    "            , skiprows=1\n",
    "            , usecols=use_col\n",
    "        )\n",
    "    t_next = datetime.datetime.now()\n",
    "    print_time(t_next, t_start, t_start)\n",
    "    \n",
    "    print()\n",
    "    print_message('NUMBER OF ROWS: {0:,}'.format(len(taxi_df)), pre_post='+', filler='-')\n",
    "    print()\n",
    "    \n",
    "    print_message('SUBSETTING DATA')\n",
    "    # apply a list of filter conditions to throw out records with missing or outlier values\n",
    "    taxi_df = taxi_df.query(' and '.join(query_frags))\n",
    "    t_curr = datetime.datetime.now()\n",
    "    print_time(t_curr, t_next, t_start)\n",
    "    t_next = t_curr\n",
    "    \n",
    "    print_message('FEATURIZING DATA')\n",
    "    taxi_df = add_features(taxi_df, gpu=1)\n",
    "    t_curr = datetime.datetime.now()\n",
    "    print_time(t_curr, t_next, t_start)\n",
    "    \n",
    "    return taxi_df, t_curr - t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CPU workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cpu_workflow(data_path):\n",
    "    t_start = datetime.datetime.now()\n",
    "    print_message('LOADING DATA')\n",
    "    \n",
    "    taxi_df = pd.read_csv(\n",
    "              os.path.join(data_path, '2016/yellow_tripdata_2016-01.csv')\n",
    "            , names=list(columns_dtypes.keys())\n",
    "            , parse_dates=True\n",
    "            , skiprows=1\n",
    "            , usecols=use_col\n",
    "        )\n",
    "    t_next = datetime.datetime.now()\n",
    "    print_time(t_next, t_start, t_start)\n",
    "    \n",
    "    print()\n",
    "    print_message('NUMBER OF ROWS: {0:,}'.format(len(taxi_df)), pre_post='+', filler='-')\n",
    "    print()\n",
    "    \n",
    "    print_message('SUBSETTING DATA')\n",
    "    # apply a list of filter conditions to throw out records with missing or outlier values\n",
    "    taxi_df = taxi_df.query(' and '.join(query_frags))\n",
    "    t_curr = datetime.datetime.now()\n",
    "    print_time(t_curr, t_next, t_start)\n",
    "    t_next = t_curr\n",
    "    \n",
    "    print_message('FEATURIZING DATA')\n",
    "    taxi_df = add_features(taxi_df, gpu=0)\n",
    "    t_curr = datetime.datetime.now()\n",
    "    print_time(t_curr, t_next, t_start)\n",
    "    \n",
    "    return t_curr - t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################# LOADING DATA #################################\n",
      "-----------------------> Step time: 0:00:01.459818, elapsed time: 0:00:01.459818\n",
      "\n",
      "-------------------------+ NUMBER OF ROWS: 10,906,858 +-------------------------\n",
      "\n",
      "############################### SUBSETTING DATA ################################\n",
      "-----------------------> Step time: 0:00:00.113333, elapsed time: 0:00:01.573151\n",
      "############################### FEATURIZING DATA ###############################\n",
      "-----------------------> Step time: 0:00:00.393898, elapsed time: 0:00:01.967049\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../../'     #### REPLACE WITH THE DATA STORE PATH\n",
    "data_path = os.path.join(data_dir, \"data/nyctaxi\")\n",
    "\n",
    "taxi_df, gpu_runtime = run_gpu_workflow(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################# LOADING DATA #################################\n",
      "-----------------------> Step time: 0:00:35.374819, elapsed time: 0:00:35.374819\n",
      "\n",
      "-------------------------+ NUMBER OF ROWS: 10,906,858 +-------------------------\n",
      "\n",
      "############################### SUBSETTING DATA ################################\n",
      "-----------------------> Step time: 0:00:02.051317, elapsed time: 0:00:37.426136\n",
      "############################### FEATURIZING DATA ###############################\n",
      "-----------------------> Step time: 0:00:15.424548, elapsed time: 0:00:52.850684\n"
     ]
    }
   ],
   "source": [
    "cpu_runtime = run_cpu_workflow(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Total CPU time: 0:00:52.850684 ########################\n",
      "######################## Total GPU time: 0:00:04.023557 ########################\n",
      "########################### Speedup over CPU: 13.135 ###########################\n"
     ]
    }
   ],
   "source": [
    "print_message('Total CPU time: {0}'.format(str(cpu_runtime)))\n",
    "print_message('Total GPU time: {0}'.format(str(gpu_runtime)))\n",
    "print_message('Speedup over CPU: {0:.3f}'.format(cpu_runtime / gpu_runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.drop(['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']).to_csv(os.path.join(data_path, '2016/featurized_yellow_tripdata_2016-01.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
