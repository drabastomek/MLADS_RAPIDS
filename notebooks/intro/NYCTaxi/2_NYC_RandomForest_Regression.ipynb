{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVIDIA RAPIDS on Azure ML\n",
    "## MLADS Fall'19\n",
    "\n",
    "In this notebook we use NYC Taxi dataset to showcase the speedup and the ease of converting code to build a Random Forest regression model on CPU and GPU.\n",
    "\n",
    "**AUTHORS**\n",
    "* Tom Drabas (Microsoft)\n",
    "* Brad Rees (NVIDIA)\n",
    "* John Zedlewski (NVIDIA)\n",
    "* Paul Mahler (NVIDIA)\n",
    "* Nick Becker (NVIDIA)\n",
    "* Chau Dang (NVIDIA)\n",
    "\n",
    "**GREATER TEAM**\n",
    "* Joshua Patterson (NVIDIA)\n",
    "* Keith Kraus (NVIDIA)\n",
    "* Michael Beaumont (NVIDIA)\n",
    "* Manuel Reyes Gomez (NVIDIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split as skTTS\n",
    "from cuml.preprocessing.model_selection import train_test_split as cumlTTS\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as skRF\n",
    "from cuml.ensemble import RandomForestRegressor as cumlRF\n",
    "\n",
    "from sklearn.metrics import r2_score as sk_r2\n",
    "from cuml.metrics.regression import r2_score as cuml_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_message(msg, length=80, filler='#', pre_post=''):\n",
    "    print(f'{pre_post} {msg} {pre_post}'.center(length, filler))\n",
    "    \n",
    "def print_time(t_curr, t_next, t_start, length=80):\n",
    "    print('> Step time: {0}, elapsed time: {1}'\n",
    "          .format(str(t_curr - t_next), str(t_curr - t_start)).rjust(length, '-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../data/nyctaxi/\n",
      "../../../data/nyctaxi/2016/featurized_yellow_tripdata_2016-01.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../../'     #### REPLACE WITH THE DATA STORE PATH\n",
    "data_path = os.path.join(data_dir, \"data/nyctaxi/\")\n",
    "dataset   = os.path.join(data_path, \"2016/featurized_yellow_tripdata_2016-01.csv\")\n",
    "\n",
    "print(data_path)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"passenger_count\",\"trip_distance\",\"pickup_longitude\",\"pickup_latitude\",\"rate_code\",\"dropoff_longitude\",\"dropoff_latitude\",\"fare_amount\",\"hour\",\"year\",\"month\",\"day\",\"diff\",\"pickup_latitude_r\",\"pickup_longitude_r\",\"dropoff_latitude_r\",\"dropoff_longitude_r\"\n",
      "2,1.1,-73.9903717,40.73469543,1,-73.98184204,40.73240662,7.5,0,2016,1,1,0,40.73,-74.0,40.73,-73.99\n",
      "5,4.9,-73.98078156,40.7299118,1,-73.94447327,40.71667862,18.0,0,2016,1,1,0,40.72,-73.99,40.71,-73.95\n",
      "1,10.54,-73.98455048,40.67956543,1,-73.95027161,40.78892517,33.0,0,2016,1,1,0,40.67,-73.99,40.78,-73.96\n",
      "1,4.75,-73.99346924,40.71899033,1,-73.96224213,40.65733337,16.5,0,2016,1,1,0,40.71,-74.0,40.65,-73.97\n",
      "3,1.76,-73.96062469,40.78133011,1,-73.9772644,40.7585144,8.0,0,2016,1,1,0,40.78,-73.97,40.75,-73.98\n",
      "2,5.52,-73.9801178,40.74304962,1,-73.9134903,40.76314163,19.0,0,2016,1,1,1110000,40.74,-73.99,40.76,-73.92\n",
      "2,7.45,-73.9940567,40.71998978,1,-73.966362,40.78987122,26.0,0,2016,1,1,1605000,40.71,-74.0,40.78,-73.97\n",
      "1,1.2,-73.97942352,40.74461365,1,-73.99203491,40.7539444,9.0,0,2016,1,1,714000,40.74,-73.98,40.75,-74.0\n",
      "1,6.0,-73.94715118,40.79104614,1,-73.92076874,40.8655777,18.0,0,2016,1,1,672000,40.79,-73.95,40.86,-73.93\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$dataset\"\n",
    "head $1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset, 'r') as f:\n",
    "    temp = f.readline()\n",
    "    ncols = len(temp.split(','))\n",
    "    del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define GPU workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_load_data(fname, ncols):\n",
    "    dtypes = [\"float32\" for i in range(ncols)]\n",
    "    return cudf.read_csv(fname, delimiter=',', dtype=dtypes)\n",
    "\n",
    "def run_gpu_workflow(fname, ncols):\n",
    "    t_start = datetime.datetime.now()\n",
    "    print_message('LOADING DATA')\n",
    "    df = gpu_load_data(fname, ncols)\n",
    "    t_next = datetime.datetime.now()\n",
    "    print_time(t_next, t_start, t_start)\n",
    "    \n",
    "    print_message('SPLITTING INTO TRAIN AND TEST')\n",
    "    X_train, X_test, y_train, y_test = cumlTTS(df, 'fare_amount', train_size=0.75)\n",
    "    t_curr = datetime.datetime.now()\n",
    "    print_time(t_curr, t_next, t_start)\n",
    "    t_next = t_curr\n",
    "    \n",
    "    print()\n",
    "    print_message('Train size: {0:,}'.format(len(X_train)), filler='-', pre_post='+')\n",
    "    print_message('Test  size: {0:,}'.format(len(X_test)), filler='-', pre_post='+')\n",
    "    print()\n",
    "    \n",
    "    print_message('FITTING MODEL')\n",
    "    model = cumlRF(\n",
    "          max_features = 1.0\n",
    "        , n_estimators = 40\n",
    "        , split_algo = 1 # global_quantile\n",
    "        , n_bins = 16\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    t_curr = datetime.datetime.now()\n",
    "    print_time(t_curr, t_next, t_start)\n",
    "    t_next = t_curr\n",
    "    \n",
    "    print()\n",
    "    print_message('PREDICTING')\n",
    "    y_hat = model.predict(X_test)\n",
    "    print()\n",
    "    print_message('R^2 of the model: {0:.4f}'.format(cuml_r2(y_test, y_hat)), filler='-', pre_post='+')\n",
    "    print()\n",
    "    \n",
    "    t_curr = datetime.datetime.now()\n",
    "    print_time(t_curr, t_next, t_start)\n",
    "    \n",
    "    return t_curr - t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CPU workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_load_data(fname, ncols):\n",
    "    return pd.read_csv(fname, delimiter=',', dtype=np.float32)\n",
    "\n",
    "def run_cpu_workflow(fname, ncols):\n",
    "    t_start = datetime.datetime.now()\n",
    "    print_message('LOADING DATA')\n",
    "    df = cpu_load_data(fname, ncols)\n",
    "    t_next = datetime.datetime.now()\n",
    "    print_time(t_next, t_start, t_start)\n",
    "    \n",
    "    print_message('SPLITTING INTO TRAIN AND TEST')\n",
    "    X = df.drop('fare_amount', axis=1)\n",
    "    y = df['fare_amount']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = skTTS(X, y, train_size=0.75)\n",
    "    t_curr = datetime.datetime.now()\n",
    "    print_time(t_curr, t_next, t_start)\n",
    "    t_next = t_curr\n",
    "    \n",
    "    print()\n",
    "    print_message('Train size: {0:,}'.format(len(X_train)), filler='-', pre_post='+')\n",
    "    print_message('Test  size: {0:,}'.format(len(X_test)), filler='-', pre_post='+')\n",
    "    print()\n",
    "    \n",
    "    print_message('FITTING MODEL')\n",
    "    model = skRF(\n",
    "          max_features = 1.0\n",
    "        , n_estimators = 40\n",
    "        , n_jobs = 4\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    t_curr = datetime.datetime.now()\n",
    "    print_time(t_curr, t_next, t_start)\n",
    "    t_next = t_curr\n",
    "    \n",
    "    print()\n",
    "    print_message('PREDICTING')\n",
    "    y_hat = model.predict(X_test)\n",
    "    print()\n",
    "    print_message('R^2 of the model: {0:.4f}'.format(sk_r2(y_test, y_hat)), filler='-', pre_post='+')\n",
    "    print()\n",
    "    \n",
    "    t_curr = datetime.datetime.now()\n",
    "    print_time(t_curr, t_next, t_start)\n",
    "    \n",
    "    return t_curr - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################# LOADING DATA #################################\n",
      "-----------------------> Step time: 0:00:00.859018, elapsed time: 0:00:00.859018\n",
      "######################## SPLITTING INTO TRAIN AND TEST #########################\n",
      "-----------------------> Step time: 0:00:01.426499, elapsed time: 0:00:02.285517\n",
      "\n",
      "---------------------------+ Train size: 7,760,776 +----------------------------\n",
      "---------------------------+ Test  size: 2,586,926 +----------------------------\n",
      "\n",
      "################################ FITTING MODEL #################################\n",
      "-----------------------> Step time: 0:02:04.595323, elapsed time: 0:02:06.880840\n",
      "\n",
      "################################## PREDICTING ##################################\n",
      "\n",
      "--------------------------+ R^2 of the model: 0.9287 +--------------------------\n",
      "\n",
      "-----------------------> Step time: 0:00:01.586121, elapsed time: 0:02:08.466961\n"
     ]
    }
   ],
   "source": [
    "gpu_runtime = run_gpu_workflow(dataset, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################# LOADING DATA #################################\n",
      "-----------------------> Step time: 0:00:11.707485, elapsed time: 0:00:11.707485\n",
      "######################## SPLITTING INTO TRAIN AND TEST #########################\n",
      "-----------------------> Step time: 0:00:02.565499, elapsed time: 0:00:14.272984\n",
      "\n",
      "---------------------------+ Train size: 7,760,776 +----------------------------\n",
      "---------------------------+ Test  size: 2,586,926 +----------------------------\n",
      "\n",
      "################################ FITTING MODEL #################################\n",
      "-----------------------> Step time: 0:16:22.040610, elapsed time: 0:16:36.313594\n",
      "\n",
      "################################## PREDICTING ##################################\n",
      "\n",
      "--------------------------+ R^2 of the model: 0.9685 +--------------------------\n",
      "\n",
      "-----------------------> Step time: 0:00:20.727196, elapsed time: 0:16:57.040790\n"
     ]
    }
   ],
   "source": [
    "cpu_runtime = run_cpu_workflow(dataset, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Total CPU time: 0:16:57.040790 ########################\n",
      "######################## Total GPU time: 0:02:08.466961 ########################\n",
      "########################### Speedup over CPU: 7.917 ############################\n"
     ]
    }
   ],
   "source": [
    "print_message('Total CPU time: {0}'.format(str(cpu_runtime)))\n",
    "print_message('Total GPU time: {0}'.format(str(gpu_runtime)))\n",
    "print_message('Speedup over CPU: {0:.3f}'.format(cpu_runtime / gpu_runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
