{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.widgets import RunDetails\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/config.json', 'r') as f:\n",
    "    config = json.loads(f.read())\n",
    "    \n",
    "subscription_id = config[\"SUBSCRIPTION_ID\"]\n",
    "resource_group = config[\"RESOURCE_GROUP\"]\n",
    "workspace_name = config[\"WORKSPACE_NAME\"]\n",
    "gpu_cluster_name = config[\"GPU_CLUSTER_NAME\"]\n",
    "\n",
    "ws = Workspace(workspace_name=workspace_name, subscription_id=subscription_id, resource_group=resource_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute target found. Using: gpu-todrabas\n"
     ]
    }
   ],
   "source": [
    "scripts_folder = \"scripts\"\n",
    "\n",
    "\n",
    "\n",
    "if gpu_cluster_name in ws.compute_targets:\n",
    "    gpu_cluster = ws.compute_targets[gpu_cluster_name]\n",
    "    \n",
    "    if gpu_cluster and type(gpu_cluster) is AmlCompute:\n",
    "        print('Compute target found. Using: ' + gpu_cluster_name)\n",
    "else:\n",
    "    print(\"Creating new cluster\")\n",
    "    \n",
    "    # vm_size parameter below could be modified to one of the RAPIDS-supported VM types\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_NC6s_v2\", min_nodes=1, max_nodes = 1)\n",
    "\n",
    "    # create the cluster\n",
    "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, provisioning_config)\n",
    "    gpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_root = 'unswiot'\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "# data already uploaded to the datastore\n",
    "data_ref = DataReference(data_reference_name='data', datastore=ds, path_on_datastore=file_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = RunConfiguration()\n",
    "run_config.framework = 'python'\n",
    "run_config.environment.python.user_managed_dependencies = True\n",
    "run_config.environment.python.interpreter_path = '/conda/envs/rapids/bin/python'\n",
    "run_config.target = gpu_cluster_name\n",
    "run_config.environment.docker.enabled = True\n",
    "run_config.environment.docker.gpu_support = True\n",
    "run_config.environment.docker.base_image = \"todrabas/mlads_rapids:latest\"\n",
    "# run_config.environment.docker.base_image = \"rapidsai/rapidsai:cuda9.2-runtime-ubuntu18.04\"\n",
    "run_config.environment.spark.precache_packages = False\n",
    "run_config.data_references={'data':data_ref.to_config()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: rapidstest_iot_flow_gpu_1559603271_3b7eae0f\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/MLADS_todrabas/providers/Microsoft.MachineLearningServices/workspaces/todrabas_MLADS_WE/experiments/rapidstest_iot_flow_gpu/runs/rapidstest_iot_flow_gpu_1559603271_3b7eae0f\n",
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Running NETWORK FLOW on GPU...\n",
      "###[ Ethernet ]### \n",
      "  dst       = 14:cc:20:51:33:ea\n",
      "  src       = 30:8c:fb:2f:e4:b2\n",
      "  type      = 0x800\n",
      "###[ IP ]### \n",
      "     version   = 4\n",
      "     ihl       = 5\n",
      "     tos       = 0x0\n",
      "     len       = 142\n",
      "     id        = 55213\n",
      "     flags     = DF\n",
      "     frag      = 0\n",
      "     ttl       = 64\n",
      "     proto     = 6\n",
      "     chksum    = 0x7ab3\n",
      "     src       = 192.168.1.106\n",
      "     dst       = 52.87.241.159\n",
      "     \\options   \\\n",
      "###[ TCP ]### \n",
      "        sport     = 40767\n",
      "        dport     = 443\n",
      "        seq       = 91355963\n",
      "        ack       = 679917399\n",
      "        dataofs   = 8\n",
      "        reserved  = 0\n",
      "        flags     = PA\n",
      "        window    = 2549\n",
      "        chksum    = 0xd703\n",
      "        urgptr    = 0\n",
      "        options   = [('NOP', None), ('NOP', None), ('Timestamp', (23325908, 4049739322))]\n",
      "###[ Raw ]### \n",
      "           load      = '\\x17\\x03\\x01\\x00 |\\xa0\\xa9\"[\\xe1\\x7f>\\x88\\xccP=\\xb6\\x1c\\xdf\\xa9u\\x82z\\xf2G\\xaaH\\x82/mV\\xac\\x97\\xe7l\\x19\\x17\\x03\\x01\\x000\\x95\\xd9\\x85wV\\xb9u\\xf7N\\xb6>\\x14\\xae\\xcf\\x9f\\xbbD\\xae\\x11\"\\xc0\\xedw\\x1c\\xfa0\\xa1:\\x85\\xa0\\xb0w+..\\x06\\x14M\\x01\\x13\\xf4\\x88\\xf4\\x19\\xa4\\x11e:'\n",
      "\n",
      "None\n",
      "Labels...\n",
      "                           device                mac  connection  category  category_id\n",
      "0                    Smart Things  d0:52:a8:00:67:5e       Wired       Hub            6\n",
      "1                     Amazon Echo  44:65:0d:56:cc:d3    Wireless   Speaker           11\n",
      "2                 Netatmo Welcome  70:ee:50:18:34:43    Wireless    Camera            1\n",
      "3  TP-Link Day Night Cloud camera  f4:f2:6d:93:51:f1    Wireless    Camera            1\n",
      "4                Samsung SmartCam  00:16:6c:ab:6b:88    Wireless    Camera            1\n",
      "Merged...\n",
      "                   ts                 uid      id.orig_h  id.orig_p      id.resp_h  id.resp_p  proto ...  resp_category_id\n",
      "0   1474563272.908724  Ct3EZ11u3O1WP75V86  192.168.1.223          8    192.168.1.1          0   icmp ...                10\n",
      "1  1474563295.4777899  Cvn7Hn1vQGZiqyMKF8  192.168.1.193          8    192.168.1.1          0   icmp ...                10\n",
      "2  1474562393.9896653  Cwd6Ea1oxBE7WWKXGb  192.168.1.239      37811   46.105.38.79       5228    tcp ...                10\n",
      "3  1474563356.1164541  CLu4PR3ocqsupkFtC4  192.168.1.240      53627  93.184.216.34         80    tcp ...                10\n",
      "4  1474563356.2826202  CZOOmx1Qp2UdsURVPk  192.168.1.240      53628  93.184.216.34         80    tcp ...                10\n",
      "[23 more columns]\n",
      "==> shape (original) = (950384, 31)\n",
      "==> shape = (1900768, 13)\n",
      "==> number of IoT categories = 13\n",
      "Check if any missing...\n",
      "ts 0\n",
      "ip 0\n",
      "port 0\n",
      "proto 0\n",
      "service 0\n",
      "duration 0\n",
      "bytes 0\n",
      "pkts 0\n",
      "ip_bytes 0\n",
      "device 341269\n",
      "mac 0\n",
      "category 341269\n",
      "category_id 341269\n",
      "After missing observations imputation...\n",
      "ts 0\n",
      "ip 0\n",
      "port 0\n",
      "proto 0\n",
      "service 0\n",
      "duration 0\n",
      "bytes 0\n",
      "pkts 0\n",
      "ip_bytes 0\n",
      "device 0\n",
      "mac 0\n",
      "category 0\n",
      "category_id 0\n",
      "==> train length = 5324\n",
      "==> test length = 2395\n",
      "libibverbs: Warning: couldn't open config directory '/etc/libibverbs.d'.\n",
      "[0]\ttrain-merror:0.124343\ttest-merror:0.163257\n",
      "[1]\ttrain-merror:0.126784\ttest-merror:0.164092\n",
      "[2]\ttrain-merror:0.120023\ttest-merror:0.158664\n",
      "[3]\ttrain-merror:0.114576\ttest-merror:0.153236\n",
      "[4]\ttrain-merror:0.112509\ttest-merror:0.150731\n",
      "[5]\ttrain-merror:0.109504\ttest-merror:0.146973\n",
      "[6]\ttrain-merror:0.106311\ttest-merror:0.142797\n",
      "[7]\ttrain-merror:0.103681\ttest-merror:0.143215\n",
      "[8]\ttrain-merror:0.10124\ttest-merror:0.14238\n",
      "[9]\ttrain-merror:0.099361\ttest-merror:0.141127\n",
      "[10]\ttrain-merror:0.095417\ttest-merror:0.137787\n",
      "[11]\ttrain-merror:0.093539\ttest-merror:0.13904\n",
      "[12]\ttrain-merror:0.092036\ttest-merror:0.137787\n",
      "[13]\ttrain-merror:0.091097\ttest-merror:0.13904\n",
      "[14]\ttrain-merror:0.090721\ttest-merror:0.138205\n",
      "[15]\ttrain-merror:0.088843\ttest-merror:0.136117\n",
      "[16]\ttrain-merror:0.088092\ttest-merror:0.136117\n",
      "[17]\ttrain-merror:0.086965\ttest-merror:0.135699\n",
      "[18]\ttrain-merror:0.08565\ttest-merror:0.133194\n",
      "[19]\ttrain-merror:0.085462\ttest-merror:0.132777\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.25259947776794434 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: rapidstest_iot_flow_gpu_1559603271_3b7eae0f\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/MLADS_todrabas/providers/Microsoft.MachineLearningServices/workspaces/todrabas_MLADS_WE/experiments/rapidstest_iot_flow_gpu/runs/rapidstest_iot_flow_gpu_1559603271_3b7eae0f\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'rapidstest_iot_flow_gpu_1559603271_3b7eae0f',\n",
       " 'target': 'gpu-todrabas',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-06-03T23:08:03.849543Z',\n",
       " 'endTimeUtc': '2019-06-03T23:08:32.206895Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': '13e3ee37-40d8-4929-b26e-065344ff7415',\n",
       "  'azureml.git.repository_uri': 'git@github.com:drabastomek/MLADS_RAPIDS.git',\n",
       "  'mlflow.source.git.repoURL': 'git@github.com:drabastomek/MLADS_RAPIDS.git',\n",
       "  'azureml.git.branch': 'devel',\n",
       "  'mlflow.source.git.branch': 'devel',\n",
       "  'azureml.git.commit': 'ba3ab5b273cbdf8a5bcd3345a4a043542de4442c',\n",
       "  'mlflow.source.git.commit': 'ba3ab5b273cbdf8a5bcd3345a4a043542de4442c',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'runDefinition': {'script': '3_Rapids_flow_classification.py',\n",
       "  'arguments': ['--data_dir', '$AZUREML_DATAREFERENCE_data'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'gpu-todrabas',\n",
       "  'dataReferences': {'data': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Mount',\n",
       "    'pathOnDataStore': 'unswiot',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment rapidstest_iot_flow_gpu Environment',\n",
       "   'version': 'Autosave_2019-06-03T22:41:41Z_f84541be',\n",
       "   'python': {'interpreterPath': '/conda/envs/rapids/bin/python',\n",
       "    'userManagedDependencies': True,\n",
       "    'condaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}],\n",
       "     'channels': ['conda-forge']},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'todrabas/mlads_rapids:latest',\n",
       "    'enabled': True,\n",
       "    'sharedVolumes': True,\n",
       "    'gpuSupport': True,\n",
       "    'shmSize': '1g',\n",
       "    'arguments': [],\n",
       "    'baseImageRegistry': {'address': None,\n",
       "     'username': None,\n",
       "     'password': None}},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False}},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'vmPriority': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None},\n",
       " 'logFiles': {'azureml-logs/80_driver_log.txt': 'https://todrabasmladsw6357972490.blob.core.windows.net/azureml/ExperimentRun/dcid.rapidstest_iot_flow_gpu_1559603271_3b7eae0f/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=AheD014oWNYchxIF0mPaa7wTEiFhuJyt5SkgdeSAVU0%3D&st=2019-06-03T22%3A58%3A34Z&se=2019-06-04T07%3A08%3A34Z&sp=r',\n",
       "  'azureml-logs/55_batchai_stdout-job_prep.txt': 'https://todrabasmladsw6357972490.blob.core.windows.net/azureml/ExperimentRun/dcid.rapidstest_iot_flow_gpu_1559603271_3b7eae0f/azureml-logs/55_batchai_stdout-job_prep.txt?sv=2018-03-28&sr=b&sig=%2Be8NwvD0%2FiotRCtRs5q%2FbzTuAh51G7nC1vvHKDSxGho%3D&st=2019-06-03T22%3A58%3A34Z&se=2019-06-04T07%3A08%3A34Z&sp=r',\n",
       "  'azureml-logs/55_batchai_execution.txt': 'https://todrabasmladsw6357972490.blob.core.windows.net/azureml/ExperimentRun/dcid.rapidstest_iot_flow_gpu_1559603271_3b7eae0f/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=jrMc0y9Jh3J2lPuMG3YurdA2PK1ww6wauMBvZI3dQag%3D&st=2019-06-03T22%3A58%3A34Z&se=2019-06-04T07%3A08%3A34Z&sp=r',\n",
       "  'azureml-logs/55_batchai_stdout-job_post.txt': 'https://todrabasmladsw6357972490.blob.core.windows.net/azureml/ExperimentRun/dcid.rapidstest_iot_flow_gpu_1559603271_3b7eae0f/azureml-logs/55_batchai_stdout-job_post.txt?sv=2018-03-28&sr=b&sig=p4RJgv4R1DKI8R3fNxj2z%2FTvZgI2D%2BSkcori6dWBNGk%3D&st=2019-06-03T22%3A58%3A34Z&se=2019-06-04T07%3A08%3A34Z&sp=r',\n",
       "  'logs/azureml/azureml.log': 'https://todrabasmladsw6357972490.blob.core.windows.net/azureml/ExperimentRun/dcid.rapidstest_iot_flow_gpu_1559603271_3b7eae0f/logs/azureml/azureml.log?sv=2018-03-28&sr=b&sig=KF70b9RjZx%2B%2FLXL6o2053wgrlxGkdbb8TfemkF6VISw%3D&st=2019-06-03T22%3A58%3A34Z&se=2019-06-04T07%3A08%3A34Z&sp=r'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = ScriptRunConfig(source_directory=scripts_folder, \n",
    "                          script='3_Rapids_flow_classification.py', \n",
    "                          arguments = ['--data_dir', str(data_ref)],\n",
    "                          run_config=run_config\n",
    "                         )\n",
    "\n",
    "exp = Experiment(ws, 'rapidstest_iot_flow_gpu')\n",
    "run = exp.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
